{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "loaded\n",
      "Loaded Done\n",
      "['sadhvika', 'shreyesh']\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "shreyesh is identified\n",
      "frame recorded\n",
      "Unknown is identified\n",
      "frame recorded\n",
      "Unknown is identified\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "TOLERANCE = 0.6  # Recognition tolerance\n",
    "FRAME_THICKNESS = 3  # Thickness of bounding box\n",
    "FONT_THICKNESS = 2  # Thickness of text\n",
    "MODEL = \"cnn\"  # The model can be \"hog\" or \"cnn\" for detection\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"loaded\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Draw bounding boxes and names\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "# Recognize faces from live video and log to CSV\n",
    "def recognize_faces_from_live_video(known_faces, known_names):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Open a CSV file for writing\n",
    "    with open('C:/attendance2/attendance_log.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Name', 'Timestamp'])  # Header row\n",
    "        \n",
    "        last_record_times = {}  # Dictionary to track last record time for each person\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process every nth frame to reduce the load\n",
    "            frame_count += 1\n",
    "            if frame_count % 5 != 0:  # Change the modulo value to adjust the frame rate\n",
    "                continue\n",
    "\n",
    "            # Detect faces with RetinaFace\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            print(\"frame recorded\")\n",
    "            # Prepare face encodings for recognition\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = []\n",
    "            face_names = []\n",
    "\n",
    "            for face_key in faces.keys():\n",
    "                facial_area = faces[face_key][\"facial_area\"]\n",
    "\n",
    "                # Append detected face locations for recognition\n",
    "                face_locations.append(facial_area)\n",
    "\n",
    "                # Convert RetinaFace coordinates to dlib format\n",
    "                top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "                # Encode the face using face_recognition\n",
    "                encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "                for encoding in encodings:\n",
    "                    # Compare with known faces\n",
    "                    matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                    name = \"Unknown\"\n",
    "\n",
    "                    # Find the shortest distance to a known face\n",
    "                    face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "                    if matches[best_match_index]:\n",
    "                        name = known_names[best_match_index]\n",
    "                    print(name, \"is identified\")\n",
    "                    face_names.append(name)\n",
    "\n",
    "            # Log detected names and timestamps if 2 minutes have passed\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            for name in face_names:\n",
    "                if name != \"Unknown\":\n",
    "                    if name not in last_record_times or (datetime.now() - last_record_times[name]) >= timedelta(minutes=2):\n",
    "                        writer.writerow([name, timestamp])\n",
    "                        last_record_times[name] = datetime.now()  # Update the last record time for this person\n",
    "\n",
    "            # Draw the results\n",
    "            draw_faces(frame, face_locations, face_names)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Live Video', frame)\n",
    "            \n",
    "            # Press 'q' to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load known faces\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    print(\"Loaded Done\")\n",
    "    print(known_names)\n",
    "    recognize_faces_from_live_video(known_faces, known_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "loaded\n",
      "Loaded Done\n",
      "['akhil', 'sadhvika', 'shreyesh', 'shreyesh', 'srinath']\n",
      "frame recorded\n",
      "frame recorded\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "TOLERANCE = 0.6  # Recognition tolerance\n",
    "FRAME_THICKNESS = 3  # Thickness of bounding box\n",
    "FONT_THICKNESS = 2  # Thickness of text\n",
    "MODEL = \"cnn\"  # The model can be \"hog\" or \"cnn\" for detection\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"loaded\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Draw bounding boxes and names\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "# Recognize faces from live video and log to CSV\n",
    "def recognize_faces_from_live_video(known_faces, known_names):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Open a CSV file for writing\n",
    "    with open('C:/attendance2/attendance_log.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Name', 'Timestamp'])  # Header row\n",
    "        \n",
    "        last_record_times = {}  # Dictionary to track last record time for each person\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process every nth frame to reduce the load\n",
    "            frame_count += 1\n",
    "            if frame_count % 10!= 0:  # Change the modulo value to adjust the frame rate\n",
    "                continue\n",
    "\n",
    "            # Detect faces with RetinaFace\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            print(\"frame recorded\")\n",
    "            # Prepare face encodings for recognition\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = []\n",
    "            face_names = []\n",
    "\n",
    "            for face_key in faces.keys():\n",
    "                facial_area = faces[face_key][\"facial_area\"]\n",
    "\n",
    "                # Append detected face locations for recognition\n",
    "                face_locations.append(facial_area)\n",
    "\n",
    "                # Convert RetinaFace coordinates to dlib format\n",
    "                top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "                # Encode the face using face_recognition\n",
    "                encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "                for encoding in encodings:\n",
    "                    # Compare with known faces\n",
    "                    matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                    name = \"Unknown\"\n",
    "\n",
    "                    # Find the shortest distance to a known face\n",
    "                    face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "                    if matches[best_match_index]:\n",
    "                        name = known_names[best_match_index]\n",
    "                    print(name, \"is identified\")\n",
    "                    face_names.append(name)\n",
    "\n",
    "            # Log detected names and timestamps if 2 minutes have passed\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            for name in face_names:\n",
    "                if name != \"Unknown\":\n",
    "                    if name not in last_record_times or (datetime.now() - last_record_times[name]) >= timedelta(minutes=2):\n",
    "                        writer.writerow([name, timestamp])\n",
    "                        last_record_times[name] = datetime.now()  # Update the last record time for this person\n",
    "\n",
    "            # Draw the results\n",
    "            draw_faces(frame, face_locations, face_names)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Live Video', frame)\n",
    "            \n",
    "            # Press 'q' to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load known faces\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    print(\"Loaded Done\")\n",
    "    print(known_names)\n",
    "    recognize_faces_from_live_video(known_faces, known_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
