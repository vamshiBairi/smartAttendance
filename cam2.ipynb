{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces\n",
      "Loaded Done\n",
      "['akhil', 'sadhvika', 'shreyesh', 'shreyesh', 'srinath']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (recognize_faces_from_camera):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Local\\Temp\\ipykernel_27584\\20586387.py\", line 69, in recognize_faces_from_camera\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame recorded from Camera 0\n",
      "Frame recorded from Camera 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (recognize_faces_from_camera):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Local\\Temp\\ipykernel_27584\\20586387.py\", line 69, in recognize_faces_from_camera\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame recorded from Camera 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "TOLERANCE = 0.6  # Recognition tolerance\n",
    "FRAME_THICKNESS = 3  # Thickness of bounding box\n",
    "FONT_THICKNESS = 2  # Thickness of text\n",
    "MODEL = \"cnn\"  # The model can be \"hog\" or \"cnn\" for detection\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Draw bounding boxes and names\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "# Recognize faces from live video\n",
    "def recognize_faces_from_camera(camera_id, known_faces, known_names, tracking_dict):\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect faces with RetinaFace\n",
    "        faces = RetinaFace.detect_faces(frame)\n",
    "        print(f\"Frame recorded from Camera {camera_id}\")\n",
    "\n",
    "        # Prepare face encodings for recognition\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = []\n",
    "        face_names = []\n",
    "\n",
    "        current_faces = set()  # To track currently detected faces\n",
    "\n",
    "        for face_key in faces.keys():\n",
    "            facial_area = faces[face_key][\"facial_area\"]\n",
    "\n",
    "            # Append detected face locations for recognition\n",
    "            face_locations.append(facial_area)\n",
    "            \n",
    "            current_faces.add(facial_area)\n",
    "            \n",
    "            # Convert RetinaFace coordinates to dlib format\n",
    "            top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "            # Encode the face using face_recognition\n",
    "            encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "            for encoding in encodings:\n",
    "                # Compare with known faces\n",
    "                matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # Find the shortest distance to a known face\n",
    "                face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "\n",
    "                if name not in tracking_dict['seen']:\n",
    "                    if camera_id == 0:\n",
    "                        # Log entry time when a person is first detected by Camera 0\n",
    "                        tracking_dict['entry_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                        tracking_dict['seen'][name] = datetime.now()\n",
    "                        tracking_dict['exit_seen'][name] = False\n",
    "                    elif camera_id == 1:\n",
    "                        # Log exit time when a person is first detected by Camera 1\n",
    "                        if not tracking_dict['exit_seen'].get(name, False):\n",
    "                            tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                            tracking_dict['exit_seen'][name] = True\n",
    "\n",
    "        # Detect absent persons and log exit times if Camera 0\n",
    "        if camera_id == 0:\n",
    "            absent_names = set(tracking_dict['seen'].keys()) - set(face_names)\n",
    "            for name in absent_names:\n",
    "                if not tracking_dict['exit_seen'][name]:\n",
    "                    if datetime.now() - tracking_dict['seen'][name] >= timedelta(minutes=2):\n",
    "                        tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                        tracking_dict['exit_seen'][name] = True\n",
    "\n",
    "        # Draw the results\n",
    "        draw_faces(frame, face_locations, face_names)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(f'Camera {camera_id}', frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # Load known faces\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    print(\"Loaded Done\")\n",
    "    print(known_names)\n",
    "\n",
    "    # Open CSV files for logging\n",
    "    with open(r'C:\\attendance2\\attendance_log.csv', mode='a', newline='') as file:\n",
    "        entry_writer = csv.writer(file)\n",
    "        exit_writer = csv.writer(file)\n",
    "\n",
    "        tracking_dict = {\n",
    "            'entry_writer': entry_writer,\n",
    "            'exit_writer': exit_writer,\n",
    "            'seen': {},  # To track when a person was last seen\n",
    "            'exit_seen': {}  # To track if exit has been recorded for the person\n",
    "        }\n",
    "\n",
    "        # Start tracking with two cameras\n",
    "        camera_ids = [0, 1]  # Adjust these based on your camera IDs\n",
    "        threads = []\n",
    "\n",
    "        for camera_id in camera_ids:\n",
    "            thread = threading.Thread(target=recognize_faces_from_camera, args=(camera_id, known_faces, known_names, tracking_dict))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Starting attendance system...\n",
      "Loading known faces...\n",
      "Finished loading known faces.\n",
      "Starting thread for Camera 0...\n",
      "Starting thread for Camera 1...\n",
      "Camera 1 started.\n",
      "Camera 0 started.\n",
      "Detected srinath on Camera 0.\n",
      "Entry logged for srinath.\n",
      "Detected akhil on Camera 0.\n",
      "Entry logged for akhil.\n",
      "Detected srinath on Camera 0.\n",
      "Detected Unknown on Camera 0.\n",
      "Entry logged for Unknown.\n",
      "Detected srinath on Camera 0.\n",
      "Detected akhil on Camera 0.\n",
      "Detected Unknown on Camera 1.\n",
      "Detected Unknown on Camera 1.\n",
      "Detected akhil on Camera 0.\n",
      "Detected Unknown on Camera 0.\n",
      "Detected Unknown on Camera 1.\n",
      "Detected Unknown on Camera 1.\n",
      "Detected Unknown on Camera 0.\n",
      "Auto exit logged for srinath.\n",
      "Detected shreyesh on Camera 1.\n",
      "Exit logged for shreyesh.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "CSV_FILE_PATH = r\"C:\\attendance2\\attendance_log.csv\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "MODEL = \"cnn\"  # Can be \"hog\" for CPU-friendly detection\n",
    "lock = threading.Lock()  # Lock to handle concurrency in file writing\n",
    "\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    print(\"Loading known faces...\")\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        person_dir = os.path.join(KNOWN_FACES_DIR, name)\n",
    "        for filename in os.listdir(person_dir):\n",
    "            filepath = os.path.join(person_dir, filename)\n",
    "            image = face_recognition.load_image_file(filepath)\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "            else:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    print(\"Finished loading known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "def recognize_faces_from_camera(camera_id, known_faces, known_names, tracking_dict):\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Camera {camera_id} failed to open.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Camera {camera_id} started.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(f\"Failed to read frame from Camera {camera_id}.\")\n",
    "            break\n",
    "\n",
    "        faces = RetinaFace.detect_faces(frame)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = []\n",
    "        face_names = []\n",
    "\n",
    "        for key in faces.keys():\n",
    "            facial_area = faces[key][\"facial_area\"]\n",
    "            face_locations.append(facial_area)\n",
    "\n",
    "            top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "            encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "            for encoding in encodings:\n",
    "                matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                name = \"Unknown\"\n",
    "                face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "\n",
    "                print(f\"Detected {name} on Camera {camera_id}.\")\n",
    "                with lock:\n",
    "                    if name not in tracking_dict['seen']:\n",
    "                        if camera_id == 0:\n",
    "                            tracking_dict['entry_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                            print(f\"Entry logged for {name}.\")\n",
    "                            tracking_dict['seen'][name] = datetime.now()\n",
    "                            tracking_dict['exit_seen'][name] = False\n",
    "                            tracking_dict['file'].flush()  # Ensure immediate write\n",
    "                        elif camera_id == 1 and not tracking_dict['exit_seen'].get(name, False):\n",
    "                            tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                            print(f\"Exit logged for {name}.\")\n",
    "                            tracking_dict['exit_seen'][name] = True\n",
    "                            tracking_dict['file'].flush()\n",
    "\n",
    "        if camera_id == 0:\n",
    "            absent_names = set(tracking_dict['seen'].keys()) - set(face_names)\n",
    "            for name in absent_names:\n",
    "                if not tracking_dict['exit_seen'][name] and datetime.now() - tracking_dict['seen'][name] >= timedelta(minutes=2):\n",
    "                    with lock:\n",
    "                        tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                        print(f\"Auto exit logged for {name}.\")\n",
    "                        tracking_dict['exit_seen'][name] = True\n",
    "                        tracking_dict['file'].flush()\n",
    "\n",
    "        draw_faces(frame, face_locations, face_names)\n",
    "        cv2.imshow(f'Camera {camera_id}', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(f\"Camera {camera_id} stopped.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting attendance system...\")\n",
    "    known_faces, known_names = load_known_faces()\n",
    "\n",
    "    with open(CSV_FILE_PATH, mode='a', newline='') as file:\n",
    "        entry_writer = csv.writer(file)\n",
    "        exit_writer = csv.writer(file)\n",
    "\n",
    "        tracking_dict = {\n",
    "            'entry_writer': entry_writer,\n",
    "            'exit_writer': exit_writer,\n",
    "            'seen': {},\n",
    "            'exit_seen': {},\n",
    "            'file': file  # Keep reference to the file for flushing\n",
    "        }\n",
    "\n",
    "        camera_ids = [0, 1]\n",
    "        threads = []\n",
    "\n",
    "        for camera_id in camera_ids:\n",
    "            print(f\"Starting thread for Camera {camera_id}...\")\n",
    "            thread = threading.Thread(target=recognize_faces_from_camera, args=(camera_id, known_faces, known_names, tracking_dict))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "    print(\"Attendance system stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Write test successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "with open(r'C:\\attendance2\\attendance_log.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Test', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "print(\"Write test successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Starting attendance system...\n",
      "Loading known faces...\n",
      "Finished loading known faces.\n",
      "Starting thread for Camera 0...\n",
      "Starting thread for Camera 1...\n",
      "Camera 1 started.\n",
      "Camera 0 started.\n",
      "Detected Unknown on Camera 0.\n",
      "Unknown IN at 2024-10-16 15:40:44.892227\n",
      "Detected Unknown on Camera 0.\n",
      "Detected akhil on Camera 0.\n",
      "akhil IN at 2024-10-16 15:40:57.790216\n",
      "Detected Unknown on Camera 0.\n",
      "Detected akhil on Camera 0.\n",
      "Detected Unknown on Camera 0.\n",
      "Detected shreyesh on Camera 0.\n",
      "shreyesh IN at 2024-10-16 15:41:26.619832\n",
      "Detected Unknown on Camera 0.\n",
      "Detected srinath on Camera 0.\n",
      "srinath IN at 2024-10-16 15:41:40.016124\n",
      "Detected shreyesh on Camera 0.\n",
      "Detected srinath on Camera 0.\n",
      "Detected Unknown on Camera 0.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import openpyxl\n",
    "\n",
    "# Directories and Constants\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "EXCEL_FILE_PATH = r\"C:\\attendance2\\Book1.xlsx\"\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2\n",
    "\n",
    "# Load known faces\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    print(\"Loading known faces...\")\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        person_dir = os.path.join(KNOWN_FACES_DIR, name)\n",
    "        for filename in os.listdir(person_dir):\n",
    "            filepath = os.path.join(person_dir, filename)\n",
    "            image = face_recognition.load_image_file(filepath)\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "            else:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    print(\"Finished loading known faces.\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Update Excel function\n",
    "def update_excel(name, subject, in_time, out_time):\n",
    "    wb = openpyxl.load_workbook(EXCEL_FILE_PATH)\n",
    "    sheet = wb.active\n",
    "\n",
    "    # Find the student row by matching the name in column A\n",
    "    student_row = None\n",
    "    for row in range(2, sheet.max_row + 1):\n",
    "        if sheet.cell(row, 1).value == name:\n",
    "            student_row = row\n",
    "            break\n",
    "\n",
    "    if student_row is None:\n",
    "        print(f\"Error: Student {name} not found in Excel.\")\n",
    "        return\n",
    "\n",
    "    # Calculate total time in minutes\n",
    "    total_time = (out_time - in_time).total_seconds() / 60\n",
    "\n",
    "    # Update the subject's data in the Excel\n",
    "    subject_col = 2 + (subject - 1) * 5  # Each subject takes 5 columns\n",
    "    print(f\"Updating {name} for subject {subject}: IN: {in_time}, OUT: {out_time}, TOTAL TIME: {total_time:.2f} mins\")\n",
    "\n",
    "    sheet.cell(student_row, subject_col).value = in_time.strftime('%H:%M:%S')\n",
    "    sheet.cell(student_row, subject_col + 1).value = out_time.strftime('%H:%M:%S')\n",
    "    sheet.cell(student_row, subject_col + 2).value = f\"{total_time:.2f} mins\"\n",
    "\n",
    "    # Increment periods attended if total time > 45 minutes\n",
    "    periods_attended = sheet.cell(student_row, subject_col + 3).value or 0\n",
    "    if total_time > 45:\n",
    "        periods_attended += 1\n",
    "    sheet.cell(student_row, subject_col + 3).value = periods_attended\n",
    "\n",
    "    # Calculate daily attendance percentage\n",
    "    total_periods_attended = sum(sheet.cell(student_row, 5 + i * 5).value or 0 for i in range(6))\n",
    "    daily_percentage = (total_periods_attended / 6) * 100\n",
    "    sheet.cell(student_row, sheet.max_column).value = f\"{daily_percentage:.2f}%\"\n",
    "\n",
    "    # Save the Excel file with updates\n",
    "    try:\n",
    "        wb.save(EXCEL_FILE_PATH)\n",
    "        print(f\"Updated attendance for {name} in subject {subject}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Excel file: {e}\")\n",
    "\n",
    "# Drawing faces function\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "# Recognizing faces from camera\n",
    "def recognize_faces_from_camera(camera_id, known_faces, known_names, tracking_dict):\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Camera {camera_id} failed to open.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Camera {camera_id} started.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(f\"Failed to read frame from Camera {camera_id}.\")\n",
    "            break\n",
    "\n",
    "        faces = RetinaFace.detect_faces(frame)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = []\n",
    "        face_names = []\n",
    "\n",
    "        for key in faces.keys():\n",
    "            facial_area = faces[key][\"facial_area\"]\n",
    "            face_locations.append(facial_area)\n",
    "\n",
    "            top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "            encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "            for encoding in encodings:\n",
    "                matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                name = \"Unknown\"\n",
    "                face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "\n",
    "                print(f\"Detected {name} on Camera {camera_id}.\")\n",
    "                if camera_id == 0:  # Camera for IN\n",
    "                    if name not in tracking_dict['in_time']:\n",
    "                        tracking_dict['in_time'][name] = datetime.now()\n",
    "                        print(f\"{name} IN at {tracking_dict['in_time'][name]}\")\n",
    "                elif camera_id == 1:  # Camera for OUT\n",
    "                    in_time = tracking_dict['in_time'].pop(name, None)\n",
    "                    if in_time:\n",
    "                        out_time = datetime.now()\n",
    "                        update_excel(name, subject=1, in_time=in_time, out_time=out_time)\n",
    "                        print(f\"{name} OUT at {out_time}\")\n",
    "\n",
    "        draw_faces(frame, face_locations, face_names)\n",
    "        cv2.imshow(f'Camera {camera_id}', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(f\"Camera {camera_id} stopped.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(\"Starting attendance system...\")\n",
    "    known_faces, known_names = load_known_faces()\n",
    "\n",
    "    tracking_dict = {'in_time': {}}\n",
    "\n",
    "    camera_ids = [0, 1]\n",
    "    threads = []\n",
    "\n",
    "    for camera_id in camera_ids:\n",
    "        print(f\"Starting thread for Camera {camera_id}...\")\n",
    "        thread = threading.Thread(target=recognize_faces_from_camera, args=(camera_id, known_faces, known_names, tracking_dict))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"Attendance system stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "   ---------------------------------------- 0.0/250.9 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/250.9 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 92.2/250.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 143.4/250.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 250.9/250.9 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
