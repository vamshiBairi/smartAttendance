{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loaded known faces\n",
      "Loaded Done\n",
      "['akhil', 'sadhvika', 'shreyesh', 'shreyesh', 'srinath']\n",
      "Frame recorded from Camera 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (recognize_faces_from_camera):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\gshreyeshreddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\gshreyeshreddy\\AppData\\Local\\Temp\\ipykernel_18644\\20586387.py\", line 69, in recognize_faces_from_camera\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame recorded from Camera 1\n",
      "Frame recorded from Camera 0\n",
      "Frame recorded from Camera 0\n",
      "Frame recorded from Camera 0\n",
      "Frame recorded from Camera 0\n",
      "Frame recorded from Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "\n",
    "# Directory containing known faces\n",
    "KNOWN_FACES_DIR = r\"C:\\attendance2\\images\"\n",
    "TOLERANCE = 0.6  # Recognition tolerance\n",
    "FRAME_THICKNESS = 3  # Thickness of bounding box\n",
    "FONT_THICKNESS = 2  # Thickness of text\n",
    "MODEL = \"cnn\"  # The model can be \"hog\" or \"cnn\" for detection\n",
    "\n",
    "# Load known faces and their encodings\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    for name in os.listdir(KNOWN_FACES_DIR):\n",
    "        for filename in os.listdir(f\"{KNOWN_FACES_DIR}/{name}\"):\n",
    "            image = face_recognition.load_image_file(f\"{KNOWN_FACES_DIR}/{name}/{filename}\")\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_faces.append(encodings[0])\n",
    "                known_names.append(name)\n",
    "    print(\"Loaded known faces\")\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Draw bounding boxes and names\n",
    "def draw_faces(frame, faces, names):\n",
    "    for (face, name) in zip(faces, names):\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), FRAME_THICKNESS)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        y_position = face[1] - 15 if face[1] - 15 > 15 else face[1] + 15\n",
    "        cv2.rectangle(frame, (face[0], face[1]), (face[2], face[1] - 35), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (face[0] + 6, y_position), font, 0.8, (255, 255, 255), FONT_THICKNESS)\n",
    "\n",
    "# Recognize faces from live video\n",
    "def recognize_faces_from_camera(camera_id, known_faces, known_names, tracking_dict):\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect faces with RetinaFace\n",
    "        faces = RetinaFace.detect_faces(frame)\n",
    "        print(f\"Frame recorded from Camera {camera_id}\")\n",
    "\n",
    "        # Prepare face encodings for recognition\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = []\n",
    "        face_names = []\n",
    "\n",
    "        current_faces = set()  # To track currently detected faces\n",
    "\n",
    "        for face_key in faces.keys():\n",
    "            facial_area = faces[face_key][\"facial_area\"]\n",
    "\n",
    "            # Append detected face locations for recognition\n",
    "            face_locations.append(facial_area)\n",
    "            \n",
    "            current_faces.add(facial_area)\n",
    "            \n",
    "            # Convert RetinaFace coordinates to dlib format\n",
    "            top, right, bottom, left = facial_area[1], facial_area[2], facial_area[3], facial_area[0]\n",
    "            # Encode the face using face_recognition\n",
    "            encodings = face_recognition.face_encodings(frame_rgb, [(top, right, bottom, left)])\n",
    "\n",
    "            for encoding in encodings:\n",
    "                # Compare with known faces\n",
    "                matches = face_recognition.compare_faces(known_faces, encoding, TOLERANCE)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # Find the shortest distance to a known face\n",
    "                face_distances = face_recognition.face_distance(known_faces, encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "\n",
    "                if name not in tracking_dict['seen']:\n",
    "                    if camera_id == 0:\n",
    "                        # Log entry time when a person is first detected by Camera 0\n",
    "                        tracking_dict['entry_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                        tracking_dict['seen'][name] = datetime.now()\n",
    "                        tracking_dict['exit_seen'][name] = False\n",
    "                    elif camera_id == 1:\n",
    "                        # Log exit time when a person is first detected by Camera 1\n",
    "                        if not tracking_dict['exit_seen'].get(name, False):\n",
    "                            tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                            tracking_dict['exit_seen'][name] = True\n",
    "\n",
    "        # Detect absent persons and log exit times if Camera 0\n",
    "        if camera_id == 0:\n",
    "            absent_names = set(tracking_dict['seen'].keys()) - set(face_names)\n",
    "            for name in absent_names:\n",
    "                if not tracking_dict['exit_seen'][name]:\n",
    "                    if datetime.now() - tracking_dict['seen'][name] >= timedelta(minutes=2):\n",
    "                        tracking_dict['exit_writer'].writerow([name, datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "                        tracking_dict['exit_seen'][name] = True\n",
    "\n",
    "        # Draw the results\n",
    "        draw_faces(frame, face_locations, face_names)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(f'Camera {camera_id}', frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # Load known faces\n",
    "    known_faces, known_names = load_known_faces()\n",
    "    print(\"Loaded Done\")\n",
    "    print(known_names)\n",
    "\n",
    "    # Open CSV files for logging\n",
    "    with open(r'C:\\attendance2\\attendance_log.csv', mode='a', newline='') as file:\n",
    "        entry_writer = csv.writer(file)\n",
    "        exit_writer = csv.writer(file)\n",
    "\n",
    "        tracking_dict = {\n",
    "            'entry_writer': entry_writer,\n",
    "            'exit_writer': exit_writer,\n",
    "            'seen': {},  # To track when a person was last seen\n",
    "            'exit_seen': {}  # To track if exit has been recorded for the person\n",
    "        }\n",
    "\n",
    "        # Start tracking with two cameras\n",
    "        camera_ids = [0, 1]  # Adjust these based on your camera IDs\n",
    "        threads = []\n",
    "\n",
    "        for camera_id in camera_ids:\n",
    "            thread = threading.Thread(target=recognize_faces_from_camera, args=(camera_id, known_faces, known_names, tracking_dict))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
